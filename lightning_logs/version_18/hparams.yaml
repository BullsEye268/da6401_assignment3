attention_method: general
beam_size: 1
cell_type: gru
decoder_layers: 1
dropout: 0.1
embedding_dim: 64
encoder_layers: 1
hidden_size: 128
learning_rate: 0.001
pad_idx: 0
src_vocab_size: 65
teacher_forcing_ratio: 0.5
tgt_vocab_size: 30
