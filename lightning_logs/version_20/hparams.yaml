attention_method: general
beam_size: 1
cell_type: gru
decoder_layers: 2
dropout: 0.2
embedding_dim: 32
encoder_layers: 2
hidden_size: 256
learning_rate: 0.001
pad_idx: 0
src_vocab_size: 65
teacher_forcing_ratio: 0.5
tgt_vocab_size: 30
