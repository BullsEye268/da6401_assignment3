{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c977afba",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6713404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d0d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_prep import load_dakshina_data \n",
    "from src.seq2seq_model import Seq2SeqTransliteration\n",
    "from src.data_prep import create_data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb13a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 44204 training examples\n",
      "Loaded 4358 validation examples\n",
      "Loaded 4502 test examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\DELL\\.conda\\envs\\DL\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | encoder   | Encoder            | 619 K  | train\n",
      "1 | decoder   | Decoder            | 626 K  | train\n",
      "2 | train_acc | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.983     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: gpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6185ae161f014382bea8f67348171c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\.conda\\envs\\DL\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\DELL\\.conda\\envs\\DL\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f87dfd5dd4b4d268915d49823e7808f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661ef570fa5f4a1b8d08aeed7f5b3ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8254359e4a9446b0935335159c1ea45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbaaa1d4a7124d5fb235aac672b60444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97f5f31bfc949ff9da9ea9cc0717781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd238463459e457c924e63a48aa4a119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bef161ba2d64530ad9421eb47ce1ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016c914364f04775b8c0784ae85dbb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d58c7f66f6470f8e1960942bbce41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222cfb3856144dadb699cb51bfba7c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a6978ddab14d92a8c26a434fc808ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50933d5efbc74573951fc02ef1db86b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbd1a1c7695445b8a873f744c02d88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3a3ca6fb5a4fea8d7ccb6c0962acb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b750dbaacac94a11b661a02745540a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79594c60e884bc5b4016a971eae98e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95488ea57a904589858d32488e1d1428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10417b7cc6254534bc1870dccc28b568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 454654\n"
     ]
    }
   ],
   "source": [
    "# Code to load the Dakshina dataset (replace with your own data loading code)\n",
    "\n",
    "train_lines, val_lines, test_lines = load_dakshina_data()\n",
    "\n",
    "# Create data loaders\n",
    "train_loader, val_loader, test_loader, src_vocab, tgt_vocab = create_data_loaders(\n",
    "    train_lines,\n",
    "    batch_size=64,\n",
    "    min_freq=1,\n",
    "    val_lines=val_lines,\n",
    "    test_lines=test_lines\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = Seq2SeqTransliteration(\n",
    "    src_vocab_size=len(src_vocab),\n",
    "    tgt_vocab_size=len(tgt_vocab),\n",
    "    embedding_dim=32,\n",
    "    hidden_size=256,\n",
    "    encoder_layers=2,\n",
    "    decoder_layers=2,\n",
    "    dropout=0.2,\n",
    "    cell_type=\"gru\",\n",
    "    learning_rate=0.001,\n",
    ")\n",
    "\n",
    "print(f'Using device: {\"gpu\" if torch.cuda.is_available() else \"cpu\"}')\n",
    "# Create trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "        pl.callbacks.ModelCheckpoint(monitor='val_char_acc', mode='max')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "trainer.save_checkpoint(f'./data/final_model_{time.strftime(r\"%m_%d__%H_%M_%S\")}')\n",
    "\n",
    "# Total number of parameters\n",
    "total_params = model.compute_parameters()\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8796428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\DELL\\.conda\\envs\\DL\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e569c04e85b4e84aa8765ab129b6df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8310022354125977     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_char_acc       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8295981287956238     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4956575334072113     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8310022354125977    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_char_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8295981287956238    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4956575334072113    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.4956575334072113,\n",
       "  'test_acc': 0.8310022354125977,\n",
       "  'test_char_acc': 0.8295981287956238}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29492838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ./data/predictions_05_17__16_46_03.tsv\n"
     ]
    }
   ],
   "source": [
    "from src.sweeper import save_predictions\n",
    "\n",
    "my_pred_arr = save_predictions(model, test_loader, src_vocab, tgt_vocab, output_path=f'./data/predictions_{time.strftime(r\"%m_%d__%H_%M_%S\")}.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b719fdc",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "## Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_prep import load_dakshina_data\n",
    "from src.sweeper import run_wandb_sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d503908",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dakshina_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Hindi data from Dakshina dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_lines, val_lines, test_lines \u001b[38;5;241m=\u001b[39m \u001b[43mload_dakshina_data\u001b[49m()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Or run a hyperparameter sweep\u001b[39;00m\n\u001b[0;32m      5\u001b[0m run_wandb_sweep(train_lines, val_lines, test_lines, num_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, cont_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbullseye2608-indian-institute-of-technology-madras/hindi-transliteration/6bo8mal9\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dakshina_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Hindi data from Dakshina dataset\n",
    "train_lines, val_lines, test_lines = load_dakshina_data()\n",
    "\n",
    "# Or run a hyperparameter sweep\n",
    "run_wandb_sweep(train_lines, val_lines, test_lines, num_runs=1, cont_id='bullseye2608-indian-institute-of-technology-madras/hindi-transliteration/6bo8mal9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f3623bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4967da3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6b48278",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a303b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from typing import Dict, List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_prep import create_data_loaders, load_dakshina_data\n",
    "from src.seq2seq_attention_model import Seq2SeqAttentionTransliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1026ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 44204 training examples\n",
      "Loaded 4358 validation examples\n",
      "Loaded 4502 test examples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_lines, val_lines, test_lines = load_dakshina_data(base_path_data='./dataset/dakshina_dataset_v1.0/')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader, val_loader, test_loader, src_vocab, tgt_vocab = create_data_loaders(\n",
    "    train_lines,\n",
    "    batch_size=64,\n",
    "    min_freq=1,\n",
    "    val_lines=val_lines,\n",
    "    test_lines=test_lines\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = Seq2SeqAttentionTransliteration(\n",
    "    src_vocab_size=len(src_vocab),\n",
    "    tgt_vocab_size=len(tgt_vocab),\n",
    "    embedding_dim=32,\n",
    "    attention_method='general',\n",
    "    hidden_size=256,\n",
    "    encoder_layers=2,\n",
    "    decoder_layers=2,\n",
    "    dropout=0.2,\n",
    "    cell_type=\"gru\",\n",
    "    learning_rate=0.001,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5efc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | encoder   | Encoder            | 1.8 M  | train\n",
      "1 | decoder   | AttentionDecoder   | 1.2 M  | train\n",
      "2 | train_acc | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "2.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 M     Total params\n",
      "11.714    Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54670602eb54114a08cbd98693d46c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dff0034ad484155b919572677fdb2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3aa38a2c4c42cd8667f2deced75fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.020\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650822209da649b1ba687017a27ff441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.172 >= min_delta = 0.0. New best score: 0.849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7b3cc33a884c4f8a8290b9c8ecec74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.156 >= min_delta = 0.0. New best score: 0.693\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3054660bbdb04e5595ab48b028b8c083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.681\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Using device: {\"cuda\" if torch.cuda.is_available() else \"cpu\"}') # Corrected \"gpu\" to \"cuda\" for torch\n",
    "# Create trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=15, # For testing, increase for actual training\n",
    "    accelerator='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=True),\n",
    "        pl.callbacks.ModelCheckpoint(monitor='val_char_acc', mode='max', filename='best_model-{epoch:02d}-{val_char_acc:.2f}')\n",
    "    ],\n",
    "    # precision=\"16-mixed\" # Optional: for mixed precision training\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "trainer.save_checkpoint(f'./data/final_model_{time.strftime(r\"%m_%d__%H_%M_%S\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test model (using the best checkpoint automatically by default if checkpoint_callback=True)\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c82c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sweeper import save_predictions\n",
    "\n",
    "my_pred_arr = save_predictions(model, test_loader, src_vocab, tgt_vocab, output_path=f'./data/predictions_{time.strftime(r\"%m_%d__%H_%M_%S\")}.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d14cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
